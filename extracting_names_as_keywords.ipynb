{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request is to extract names of cities / vilages / towns from 11 districts aroud a client business area. It's help to create list of new key-words for GoogleAds to improve geo-targetting campaigns. The most available data comes from GUS - Polish Statistic Major Office. Let's start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing usefull liblaries\n",
    "\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of all paths to all files which we have downloaded\n",
    "\n",
    "path = \"/Users/kamiljablonski/Documents/GitHub/new_key_words_to_GoogleAds/data\"\n",
    "all_files = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating for statment to open all csv files and create master-DF with DF's containing data from all files\n",
    "# IMPORTANT: in GUSs csv files delimiter is ';' and first 5 rows are kind of distription\n",
    "# we have to set 'skiprows' and 'delimiter' args\n",
    "\n",
    "list_of_files = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, skiprows=5, index_col=None, delimiter=';')\n",
    "    list_of_files.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concating all DF's from list in one DF: frame\n",
    "\n",
    "frame = pd.concat(list_of_files , axis=0, ignore_index=True)\n",
    "\n",
    "# exctracting important for us column 'NAZWA' and finding unique values of this in one line\n",
    "unique_cities = list(frame.NAZWA.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display unique_cities to evaluate our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rawski',\n",
       " 'Biała Rawska',\n",
       " 'Cielądz',\n",
       " 'Rawa Mazowiecka',\n",
       " 'Regnów',\n",
       " 'Sadkowice',\n",
       " 'łowicki',\n",
       " 'Bielawy',\n",
       " 'Chąśno',\n",
       " 'Domaniewice',\n",
       " 'Kiernozia',\n",
       " 'Kocierzew Południowy',\n",
       " 'Łowicz',\n",
       " 'Łyszkowice',\n",
       " 'Nieborów',\n",
       " 'Zduny',\n",
       " 'sochaczewski',\n",
       " 'Brochów',\n",
       " 'Iłów',\n",
       " 'Młodzieszyn',\n",
       " 'Nowa Sucha',\n",
       " 'Rybno',\n",
       " 'Sochaczew',\n",
       " 'Teresin',\n",
       " 'pruszkowski',\n",
       " 'Brwinów',\n",
       " 'Michałowice',\n",
       " 'Nadarzyn',\n",
       " 'Piastów',\n",
       " 'Pruszków',\n",
       " 'Raszyn',\n",
       " 'Warszawa',\n",
       " 'Bemowo',\n",
       " 'Białołęka',\n",
       " 'Bielany',\n",
       " 'Mokotów',\n",
       " 'Ochota',\n",
       " 'Praga-Południe',\n",
       " 'Praga-Północ',\n",
       " 'Rembertów',\n",
       " 'Śródmieście',\n",
       " 'Targówek',\n",
       " 'Ursus',\n",
       " 'Ursynów',\n",
       " 'Wawer',\n",
       " 'Wesoła',\n",
       " 'Wilanów',\n",
       " 'Włochy',\n",
       " 'Wola',\n",
       " 'Żoliborz',\n",
       " 'żyrardowski',\n",
       " 'Mszczonów',\n",
       " 'Puszcza Mariańska',\n",
       " 'Radziejowice',\n",
       " 'Wiskitki',\n",
       " 'Żyrardów',\n",
       " 'grójecki',\n",
       " 'Belsk Duży',\n",
       " 'Błędów',\n",
       " 'Chynów',\n",
       " 'Goszczyn',\n",
       " 'Grójec',\n",
       " 'Jasieniec',\n",
       " 'Mogielnica',\n",
       " 'Nowe Miasto nad Pilicą',\n",
       " 'Pniewy',\n",
       " 'Warka',\n",
       " 'grodziski',\n",
       " 'Baranów',\n",
       " 'Grodzisk Mazowiecki',\n",
       " 'Jaktorów',\n",
       " 'Milanówek',\n",
       " 'Podkowa Leśna',\n",
       " 'Żabia Wola',\n",
       " 'warszawski zachodni',\n",
       " 'Błonie',\n",
       " 'Izabelin',\n",
       " 'Kampinos',\n",
       " 'Leszno',\n",
       " 'Łomianki',\n",
       " 'Ożarów Mazowiecki',\n",
       " 'Stare Babice',\n",
       " 'Skierniewice',\n",
       " 'sieradzki',\n",
       " 'Błaszki',\n",
       " 'Brąszewice',\n",
       " 'Brzeźnio',\n",
       " 'Burzenin',\n",
       " 'Goszczanów',\n",
       " 'Klonowa',\n",
       " 'Sieradz',\n",
       " 'Warta',\n",
       " 'Wróblew',\n",
       " 'Złoczew']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(unique_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our list still contains unwanted data which is district names. They have one fundamental difference - names of cities are upper but districts names are lower. So we can build for statment using this knowlage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing unique_cities by for statment which extracting just upper-starting cities names\n",
    "\n",
    "clear_unique_cities = []\n",
    "\n",
    "for city in unique_cities:\n",
    "    if city[0].isupper():\n",
    "        clear_unique_cities.append(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look for our result to make sure we obtained acceptable result / clear_unique_cities are not DataFrame, so we can not use head() function, but by simply indexing we can check if all went well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Biała Rawska', 'Cielądz', 'Rawa Mazowiecka', 'Regnów', 'Sadkowice']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clear_unique_cities[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's seems working - there is no 'rawski' before 'Biała Rawska' anymore. Last thing we have to do is importing our list to readable, non-python friendly file for example '.xlsx'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_unique_cities = pd.DataFrame(clear_unique_cities)    \n",
    "clear_unique_cities.to_excel('cities_names.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can send it to client paid-marketing agency and wish them fun with creating new advertising displaing in Google by new key-words we've prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
